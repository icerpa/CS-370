# CS-370

# Briefly explain the work that you did on this project: What code were you given? What code did you create yourself?

For this project, I worked on designing and training an intelligent agent to solve a maze using reinforcement learning and neural networks. I was given a foundational codebase that included the maze environment and some structural components for the agent. From there, I created the training loop, implemented the epsilon-greedy strategy, tuned hyperparameters like batch size and training epochs, and integrated experience replay to stabilize learning. These additions allowed the agent to learn from scratch and eventually reach a 100% win rate navigating the maze.

The pirate agent project helped me connect abstract concepts like Q-values, policy optimization, and exploration strategies to a real-world problem that required iterative refinement and careful design.

# What do computer scientists do and why does it matter?

Throughout my courses at SNHU I've learned that computer science is about building systems that solve problems: sometimes through algorithms, sometimes through architecture, and often through collaboration. It matters because these systems shape how we live, communicate, and make decisions. Whether we’re designing a learning agent or a user-facing application, the work we do has ripple effects far beyond the code itself.

# How do I approach a problem as a computer scientist?

As a computer scientist, I’ve learned to approach problems by breaking them down into smaller parts, testing assumptions, and iterating toward a solution. This project had its challenges for me and it reminded me to focus my debugging on understanding behavior, refining logic, and staying curious about what’s not working yet. 

# What are my ethical responsibilities to the end user and the organization?

Finally, this course has helped me reflect on the ethical responsibilities that come with building intelligent systems. We don’t just serve the end user, we shape their experience. That means being transparent about how systems learn, protecting user data, and designing with fairness and accessibility in mind. It also means being accountable to the organizations we work with, ensuring that our solutions align with their values and long-term goals. 
